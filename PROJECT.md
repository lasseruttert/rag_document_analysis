# RAG Document Analysis Project

## ProjektÃ¼bersicht

Dieses Projekt implementiert ein **Retrieval-Augmented Generation (RAG) System** zur Dokumentenanalyse. Das System ermÃ¶glicht es, Textdokumente zu ingestieren, sie semantisch durchsuchbar zu machen und auf Basis der Inhalte Fragen zu beantworten.

### Technologie-Stack
- **Python 3.x** mit PyTorch/CUDA-UnterstÃ¼tzung
- **Sentence Transformers** fÃ¼r Embedding-Generierung (Modell: all-MiniLM-L6-v2)
- **ChromaDB** als Vektordatenbank fÃ¼r semantische Suche
- **Hugging Face Transformers** mit T5-Modell (google/flan-t5-base) fÃ¼r Antwortgenerierung
- **Streamlit** fÃ¼r die Web-Interface

## Projektstruktur

```
rag_document_analysis/
â”œâ”€â”€ README.md                    # Conda/pip Installationsanweisungen
â”œâ”€â”€ test.py                      # Dependency-Test-Skript
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py        # Streamlit Web-Interface
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_texts/              # Eingabetextdateien
â”‚   â”‚   â”œâ”€â”€ kubernetes_basics.txt
â”‚   â”‚   â””â”€â”€ python_best_practices.txt
â”‚   â”œâ”€â”€ processed/              # (Leer - fÃ¼r verarbeitete Daten)
â”‚   â””â”€â”€ vectordb/              # ChromaDB Persistenz-Layer
â”‚       â”œâ”€â”€ chroma.sqlite3
â”‚       â””â”€â”€ [UUID-Ordner]/     # Vektor-Indizes
â””â”€â”€ src/                       # Hauptimplementierung
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py              # (Leer - fÃ¼r Konfiguration)
    â”œâ”€â”€ text_processor.py      # Textverarbeitung und Chunking
    â”œâ”€â”€ embeddings.py          # Embedding-Generierung
    â”œâ”€â”€ vectorstore.py         # ChromaDB-Integration
    â”œâ”€â”€ retriever.py           # Semantische Suche
    â”œâ”€â”€ llm_handler.py         # T5-basierte Antwortgenerierung
    â””â”€â”€ pipeline.py            # RAG-Pipeline-Orchestrierung
```

## Implementierte Module

### 1. Text Processing (`src/text_processor.py`) ğŸ†• **ERWEITERT**

**FunktionalitÃ¤t:**
- **Multi-Format-Support**: TXT, PDF, DOCX mit automatischer Format-Erkennung
- **PDF-Verarbeitung**: Dual-Parser-Strategie (pdfplumber + PyMuPDF fallback)
- **DOCX-Verarbeitung**: Struktur-erhaltende Extraktion mit python-docx
- **Tabellen-Extraktion**: Strukturierte Konvertierung von PDF/DOCX-Tabellen
- Chunking von Texten in Ã¼berlappende Segmente (Standard: 1000 Zeichen mit 200 Zeichen Ãœberlappung)
- **Erweiterte Metadaten**: Dateiname, Dateityp, Position, Chunk-ID, Chunk-GrÃ¶ÃŸe
- **DateigrÃ¶ÃŸe-Validierung**: 50MB Limit mit Logging
- **Robuste Error-Behandlung**: Encoding-Fallbacks, Permission-Handling

**Wichtige Funktionen:**
- `load_all_files(directory_path)`: LÃ¤dt alle unterstÃ¼tzten Dateitypen
- `load_pdf_files(directory_path)`: PDF-spezifische Verarbeitung
- `load_docx_files(directory_path)`: DOCX-spezifische Verarbeitung
- `load_text_files_extended(directory_path)`: Erweiterte TXT-Verarbeitung
- `chunk_text(text, filename, chunk_size, chunk_overlap, file_type)`: Erweiterte Chunking-Funktion
- `process_documents(directory_path)`: VollstÃ¤ndige Multi-Format-Dokumentenverarbeitung
- `validate_file_size(file_path)`: DateigrÃ¶ÃŸe-Validierung
- `safe_file_processing(file_path, processor_func)`: Sichere Dateiverarbeitung

**Status:** âœ… VollstÃ¤ndig implementiert mit Multi-Format-Support und umfassendem Testing

### 2. Embedding Management (`src/embeddings.py`)

**FunktionalitÃ¤t:**
- Initialisiert Sentence Transformer Modell (all-MiniLM-L6-v2)
- GPU/CPU-automatische Erkennung und Konfiguration
- Batch-weise Embedding-Generierung fÃ¼r Performance-Optimierung
- Embedding-Dimension: 384

**Wichtige Funktionen:**
- `EmbeddingManager.__init__(model_name, use_gpu)`: Modell-Initialisierung
- `generate_embeddings(chunks, batch_size)`: Batch-Embedding-Generierung

**Status:** âœ… VollstÃ¤ndig implementiert mit Test-Pipeline

### 3. Vector Store Management (`src/vectorstore.py`)

**FunktionalitÃ¤t:**
- ChromaDB-Integration mit persistenter Speicherung
- Collection-Management fÃ¼r verschiedene Dokumentensets
- Automatic Directory-Erstellung fÃ¼r Datenbankpfad
- Embedding-Storage mit Metadaten

**Wichtige Funktionen:**
- `VectorStoreManager.__init__(storage_path)`: ChromaDB-Client-Initialisierung
- `create_or_get_collection(name)`: Collection-Management
- `add_documents(chunks_with_embeddings)`: Dokument-Speicherung

**Status:** âœ… VollstÃ¤ndig implementiert mit Verifikations-Logik

### 4. Semantic Retrieval (`src/retriever.py`)

**FunktionalitÃ¤t:**
- Query-Embedding-Generierung
- Semantische Ã„hnlichkeitssuche in ChromaDB
- Top-K Retrieval mit Distanz-Scoring
- Formatierte Ergebnis-RÃ¼ckgabe mit Metadaten

**Wichtige Funktionen:**
- `retrieve(query, top_k)`: Hauptretrieval-Funktion
- Automatische Query-zu-Vektor-Konvertierung
- Distanz-basierte Relevanz-Bewertung

**Status:** âœ… VollstÃ¤ndig implementiert mit Test-Queries

### 5. LLM Handler (`src/llm_handler.py`)

**FunktionalitÃ¤t:**
- T5-Modell-Integration (google/flan-t5-base)
- Context-Aware Antwortgenerierung
- Deutschsprachige Prompt-Templates
- Beam Search fÃ¼r verbesserte AntwortqualitÃ¤t

**Wichtige Funktionen:**
- `generate_answer(query, context_chunks)`: Hauptantwort-Generierung
- Context-Aggregation aus multiplen Chunks
- Fallback fÃ¼r fehlenden Kontext

**Konfiguration:**
- Max Input Length: 2048 Tokens
- Max Output Length: 512 Tokens
- Beam Search: 5 Beams
- Early Stopping aktiviert

**Status:** âœ… VollstÃ¤ndig implementiert mit End-to-End Test

### 6. RAG Pipeline (`src/pipeline.py`)

**FunktionalitÃ¤t:**
- Orchestrierung aller RAG-Komponenten
- Einmalige Dokumenten-Ingestion
- End-to-End Query-Processing
- Konfigurierbare Modell-Parameter

**Pipeline-Schritte:**
1. Dokumenten-Verarbeitung â†’ Chunking
2. Embedding-Generierung
3. Vektordatenbank-Speicherung
4. Query-Processing â†’ Retrieval â†’ LLM-Generierung

**Wichtige Funktionen:**
- `ingest_documents()`: VollstÃ¤ndige Dokumenten-Pipeline
- `answer_query(query, top_k)`: End-to-End Antwortgenerierung

**Status:** âœ… VollstÃ¤ndig implementiert mit Beispiel-Queries

### 7. Streamlit Web Interface (`app/streamlit_app.py`) ğŸ†• **ERWEITERT**

**FunktionalitÃ¤t:**
- Web-basierte BenutzeroberflÃ¤che mit verbesserter UX
- **Multi-Format-Upload**: TXT, PDF, DOCX mit Typ-Validierung
- **Enhanced Upload-Feedback**: Typ-Icons, Upload-Statistiken, Fehler-Handling
- Dokumenten-Ingestion mit Progress-Bars und Status-Updates
- **Erweiterte Query-Interface**: Expandable Context-Chunks mit Metadaten

**Features:**
- **Smart Sidebar**: Dokumenttyp-Statistiken, Upload-Zusammenfassung
- Upload-Verzeichnis: `data/raw_texts` (Multi-Format)
- **Progress-Tracking**: Echtzeit-Status fÃ¼r Ingestion-Prozess
- **Enhanced Context-Display**: File-Type-Icons, Relevanz-Scores, Chunk-Details
- **Metadata-Rich UI**: Position, Chunk-GrÃ¶ÃŸe, Distanz-Metriken
- Cached RAG-Pipeline fÃ¼r Performance

**Status:** âœ… VollstÃ¤ndig implementiert mit Multi-Format-Support und verbesserter UX

## Datenbasis

### Aktuell verfÃ¼gbare Dokumente:
1. **kubernetes_basics.txt**: Kubernetes-Grundlagen (Pods, Services, Deployments, ConfigMaps)
2. **python_best_practices.txt**: Python-Best-Practices (PEP 8, virtuelle Umgebungen, Type Hints, Testing)

### Vektordatenbank:
- **Typ:** ChromaDB persistent storage
- **Speicherort:** `data/vectordb/`
- **Collections:** Separate Collections fÃ¼r verschiedene Dokumentensets mÃ¶glich
- **Index-Status:** 4 UUID-basierte Indizes vorhanden (vermutlich fÃ¼r verschiedene Dokumenten-Chunks)

## Setup und Installation

### Dependencies (aus README.md):
```bash
# Conda Packages
conda install pytorch torchvision pytorch-cuda=11.8 -c pytorch -c nvidia
conda install pandas numpy scikit-learn jupyter

# Pip Packages
pip install sentence-transformers chromadb langchain
pip install pypdf2 python-docx python-dotenv streamlit
pip install pdfplumber>=3.0.0 PyMuPDF>=1.23.0  # ğŸ†• Neu hinzugefÃ¼gt
```

### Test-Skript (`test.py`) ğŸ†• **ERWEITERT**:
- ÃœberprÃ¼ft alle kritischen Dependencies (inkl. pdfplumber, PyMuPDF)
- GPU/CUDA-VerfÃ¼gbarkeit-Test
- **Dokumenten-Parser-Tests**: PDF/DOCX-Parsing-FÃ¤higkeiten
- **Erweiterte Dokumentverarbeitung**: Multi-Format-Processing-Tests
- **Dateityp-Validierung**: GrÃ¶ÃŸen-Limits und Error-Handling
- **System-Integration-Test**: End-to-End-Validierung mit neuen Metadaten
- Sentence Transformer Modell-Download-Test
- Embedding-Dimensions-Verifikation (384D)

## Architektur-Design

### RAG-Flow: ğŸ†• **ERWEITERT**
1. **Ingestion Phase:**
   - **Multi-Format-Dokumente** (TXT/PDF/DOCX) â†’ **Format-spezifische Extraktion** â†’ Chunking â†’ Embeddings â†’ Vektordatenbank (mit Dateityp-Metadaten)

2. **Query Phase:**
   - User Query â†’ Query Embedding â†’ Ã„hnlichkeitssuche â†’ Top-K Retrieval â†’ **Enhanced Context** (mit Dateityp-Info) â†’ LLM Context â†’ Antwortgenerierung

### ModularitÃ¤t:
- Jede Komponente ist eigenstÃ¤ndig testbar
- Klare Trennung zwischen Verarbeitung, Speicherung und Generierung
- Dependency Injection fÃ¼r flexible Konfiguration

## Aktuelle EinschrÃ¤nkungen ğŸ†• **REDUZIERT**

1. ~~**Textformat-Limitation:** Nur .txt-Dateien unterstÃ¼tzt~~ âœ… **BEHOBEN**: VollstÃ¤ndiger Multi-Format-Support (TXT/PDF/DOCX)
2. **Sprachmodell:** T5-base ist relativ klein fÃ¼r komplexe Reasoning-Aufgaben
3. **Chunking-Strategie:** Simple character-based chunking ohne semantische Grenzen *(NÃ¤chste PrioritÃ¤t: P1.2)*
4. **Evaluation:** Keine Metriken fÃ¼r Retrieval-QualitÃ¤t oder Antwort-Evaluation
5. **Neue EinschrÃ¤nkungen:**
   - **DateigrÃ¶ÃŸe-Limit:** 50MB pro Datei
   - **Bildinhalt:** PDFs/DOCX mit Bildern/Diagrammen werden nur als Text extrahiert
   - **Komplexe Layouts:** Sehr spezielle PDF-Formate kÃ¶nnten Parsing-Probleme haben

## Implementierungs-Status ğŸ†•

### âœ… Abgeschlossen (Januar 2025):
- **P1.1 Multi-Format-Support**: PDF/DOCX/TXT-Verarbeitung vollstÃ¤ndig implementiert
- **Enhanced UI**: File-Type-Icons, Progress-Tracking, Metadaten-Display
- **Robuste Error-Behandlung**: GrÃ¶ÃŸen-Validierung, Encoding-Fallbacks, Logging
- **Comprehensive Testing**: Multi-Format-Tests, System-Integration, Metadaten-Validierung

### ğŸ”„ NÃ¤chste PrioritÃ¤t:
- **P1.2 Verbessertes Chunking**: Semantisches Chunking mit spaCy/NLTK (siehe PLAN.md)
- **P1.3 Konfigurationssystem**: YAML-basierte Einstellungen ohne Code-Ã„nderungen

## Zusammenfassung

**Projektreife:** Production-ready fÃ¼r lokale Dokumentenanalyse mit **vollstÃ¤ndigem Multi-Format-Support** (TXT/PDF/DOCX) und erweiterten UI-Features. Das System ist bereit fÃ¼r den produktiven Einsatz und systematische Erweiterung gemÃ¤ÃŸ PLAN.md.

**Wichtigste Verbesserungen (Januar 2025):**
- ğŸ“„ **Multi-Format-Verarbeitung**: PDF (pdfplumber + PyMuPDF) und DOCX (python-docx) vollstÃ¤ndig integriert
- ğŸ—‚ï¸ **Tabellen-Extraktion**: Strukturierte Konvertierung von PDF/DOCX-Tabellen zu Text
- ğŸ¯ **Enhanced UI**: File-Type-Icons, Upload-Statistiken, Progress-Tracking, erweiterte Metadaten
- ğŸ›¡ï¸ **Robuste Error-Behandlung**: 50MB File-Size-Limits, Encoding-Fallbacks, umfassendes Logging
- âœ… **Comprehensive Testing**: Multi-Format-Tests, System-Integration, Metadaten-Validierung

Das RAG-System unterstÃ¼tzt jetzt alle gÃ¤ngigen Dokumentformate und bietet eine professionelle, benutzerfreundliche OberflÃ¤che fÃ¼r die Dokumentenanalyse.
